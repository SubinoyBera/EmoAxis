{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkthZWhdp1K-"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAaQ75olsCko",
        "outputId": "2fc3bcc0-6950-4d99-cf7c-5e41859ee22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Download pretrained RoBERTa-base\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_base = AutoModel.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47WktUNBsChQ",
        "outputId": "121ad8d9-ebc2-4dc1-8db5-1f603e864b35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "roberta_base.config.hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54IHWfunsCey"
      },
      "outputs": [],
      "source": [
        "# Remove the pooler layer\n",
        "roberta_base.pooler = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_BufptBswex"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "import torch\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54bHtqaJsCTM"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(r\"/content/emopillar_train.csv\")\n",
        "df_val = pd.read_csv(r\"/content/emopillar_validation.csv\")\n",
        "df_test = pd.read_csv(r\"/content/emopillar_testing.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJHafTR2Gt80",
        "outputId": "531327e9-d47b-485a-bb25-403afc02e96c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77477, 61)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQyUDo4tsCP0"
      },
      "outputs": [],
      "source": [
        "class EmoPillars_Dataset(Dataset):\n",
        "    def __init__(self, data: pd.DataFrame, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.max_len = 64\n",
        "        self.target_cols = [str(i) for i in range(28)]\n",
        "        self.soft_target_cols = [str(f\"{i}_exp\") for i in range(28)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return(len(self.data))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        text = str(item.utterance)\n",
        "        encoding = self.tokenizer.encode_plus(text,\n",
        "                                            add_special_tokens=True,\n",
        "                                            truncation=True,\n",
        "                                            return_tensors='pt',\n",
        "                                            max_length=self.max_len,\n",
        "                                            padding='max_length',\n",
        "                                            return_attention_mask=True)\n",
        "\n",
        "        # convert \"['...']\" → ['...']\n",
        "        labels = ast.literal_eval(item.emotions_used_to_generate_context)\n",
        "        expressiveness = ast.literal_eval(item.expressiveness)\n",
        "        #expressiveness = [float(x) for x in expressiveness]\n",
        "\n",
        "        target = torch.tensor(item[self.target_cols].values.astype('float32'))\n",
        "        soft_target = torch.tensor(item[self.soft_target_cols].values.astype('float32'))\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"atten_masks\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"label_names\": labels,\n",
        "            \"expressiveness\": expressiveness,\n",
        "            \"hard_target\": target,\n",
        "            \"soft_target\": soft_target\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adhROw77sCNY"
      },
      "outputs": [],
      "source": [
        "data = EmoPillars_Dataset(df_train, roberta_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PCH-eYisCKw",
        "outputId": "8b60c9ea-d148-4611-eead-4adec9386c86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77477"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaH52wF4tdEk",
        "outputId": "444f9345-b6f0-4638-a89a-334e6e60d444"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([   0,  100,  399,   75, 1057, 7738,    7,   28,   98,  490,    8, 5322,\n",
              "           59,   39, 6453,    4,    2,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1]),\n",
              " 'atten_masks': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'label_names': ['surprise', 'admiration', 'curiosity'],\n",
              " 'expressiveness': [0.8, 0.6, 0.3],\n",
              " 'hard_target': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
              " 'soft_target': tensor([0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000,\n",
              "         0.0000])}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data.__getitem__(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Handles:\n",
        "    - input_ids and attention_mask → padded properly\n",
        "    - emotion_labels and expressiveness → keeps as list (no stacking)\n",
        "    \"\"\"\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_masks = [item['atten_masks'] for item in batch]\n",
        "    emotion_labels = [item['label_names'] for item in batch]\n",
        "    expressiveness = [item['expressiveness'] for item in batch]\n",
        "    hard_target = [item['hard_target'] for item in batch]       # tensor [num_classes]\n",
        "    soft_target = [item['soft_target'] for item in batch]       # tensor [num_classes]\n",
        "\n",
        "    # Pad input_ids and attention masks\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
        "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
        "    hard_targets = torch.stack(hard_target, dim=0)\n",
        "    soft_targets = torch.stack(soft_target, dim=0)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'atten_masks': attention_masks,\n",
        "        'label_names': emotion_labels,            # keep as list\n",
        "        'expressiveness': expressiveness,          # keep as list\n",
        "        'hard_target': hard_targets,\n",
        "        'soft_target': soft_targets\n",
        "    }"
      ],
      "metadata": {
        "id": "JxZkunwzQziS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9dRyoVRtb7_"
      },
      "outputs": [],
      "source": [
        "# Data Loaders\n",
        "train_dataloader = DataLoader(EmoPillars_Dataset(df_train, roberta_tokenizer), batch_size=32, num_workers=4, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_dataloader = DataLoader(EmoPillars_Dataset(df_val, roberta_tokenizer), batch_size=32, num_workers=4, collate_fn=custom_collate_fn)\n",
        "test_dataloader = DataLoader(EmoPillars_Dataset(df_test, roberta_tokenizer), batch_size=32, num_workers=4, collate_fn=custom_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4WcDTvqtrwO"
      },
      "outputs": [],
      "source": [
        "# Load Precomputed Label Embeddings (JSON → Tensor)\n",
        "with open(\"/content/label_embeddings.json\", \"r\") as f:\n",
        "    emo_embed_raw = json.load(f)\n",
        "\n",
        "# Convert lists -> torch tensors (float32)\n",
        "emo_embed = {}\n",
        "for k, v in emo_embed_raw.items():\n",
        "    emo_embed[str(k)] = torch.tensor(v, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UR9nxG0trsz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.amp.autocast_mode import autocast\n",
        "from torch.amp.grad_scaler import GradScaler\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJSeRZpVtrqq"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZU-xZLHtroJ"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Text Encoder:\n",
        "    - Takes in tokenized text (from tokenizer)\n",
        "    - Generates the text embedding vector\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder):\n",
        "        super().__init__()\n",
        "        self.encoder = base_encoder\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        inputs: tokenizer output dict (input_ids, attention_mask)\n",
        "        \"\"\"\n",
        "        outputs = self.encoder(**inputs, output_hidden_states=True)\n",
        "        last_hidden_state = outputs.hidden_states[-1]                                                                   # [B, T, H]\n",
        "\n",
        "        atten_mask = inputs['attention_mask']                                                                           # [B, T]\n",
        "        # Mean pooling text_embeddings\n",
        "        atten_mask = atten_mask.unsqueeze(-1).float()\n",
        "        pooled_text_emb = (last_hidden_state * atten_mask).sum(dim=1) / atten_mask.sum(dim=1).clamp(min=1e-9)           # [B, H]\n",
        "\n",
        "        return {\n",
        "            \"text_embed\": pooled_text_emb,\n",
        "            \"last_hidden_state\": last_hidden_state,\n",
        "            \"atten_mask\": atten_mask\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-sJhLgFuYSW"
      },
      "outputs": [],
      "source": [
        "class CrossAttentionModule(nn.Module):\n",
        "    def __init__(self, label_embedding_dict):\n",
        "        super().__init__()\n",
        "\n",
        "        self.label_embedding_dict = {\n",
        "            k: v.clone().detach() for k, v in label_embedding_dict.items()\n",
        "        }\n",
        "        # Multi-head cross attention\n",
        "        self.cross_attn = nn.MultiheadAttention(\n",
        "            embed_dim=768,\n",
        "            num_heads=6,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(768)\n",
        "\n",
        "    def forward(self, encoder_out, emotion_labels, expressiveness):\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        emotion_emb = []\n",
        "        for labels, weights in zip(emotion_labels, expressiveness):\n",
        "            # stack embeddings of all emotion descriptions\n",
        "            emb_list = [self.label_embedding_dict[lbl].to(device) for lbl in labels]\n",
        "            emb_stack = torch.stack(emb_list, dim=0)                                                       # [num_labels, H]\n",
        "\n",
        "            # normalize weights → weighted mean\n",
        "            w = torch.tensor(weights, dtype=torch.float32, device=device).unsqueeze(1)\n",
        "            w = w / w.sum()\n",
        "            weighted_emb = (emb_stack * w).sum(dim=0)                                                      # [H]\n",
        "            emotion_emb.append(weighted_emb)\n",
        "\n",
        "        emotion_emb = torch.stack(emotion_emb, dim=0).unsqueeze(1)                                         # [B, 1, H]\n",
        "\n",
        "        # cross-attention (query=text, key/value=emotion)\n",
        "        attn_out, _ = self.cross_attn(\n",
        "            query = encoder_out[\"last_hidden_state\"],                     # [B, T, H]\n",
        "            key = emotion_emb,                                            # [B, 1, H]\n",
        "            value = emotion_emb                                           # [B, 1, H]\n",
        "        )\n",
        "\n",
        "        # Fuse and pool\n",
        "        fused_hidden_state = encoder_out[\"last_hidden_state\"] + attn_out\n",
        "        atten_mask = encoder_out[\"atten_mask\"]\n",
        "        fused_emo_text_emb = (fused_hidden_state * atten_mask).sum(dim=1) / atten_mask.sum(dim=1).clamp(min=1e-9)\n",
        "        fused_emo_text_emb = self.layer_norm(fused_emo_text_emb)\n",
        "\n",
        "        return fused_emo_text_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHmJC2rkudVl"
      },
      "outputs": [],
      "source": [
        "class PosteriorNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Learns an emotion-aware posterior distribution q(z | x, e)\n",
        "    over latent space using fused encoder output.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=768, latent_dim=128):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(256)\n",
        "        )\n",
        "        self.mu_posterior = nn.Linear(256, latent_dim)\n",
        "        self.logvar_posterior = nn.Linear(256, latent_dim)\n",
        "\n",
        "    def forward(self, fused_emo_text_emb):\n",
        "        h = self.mlp(fused_emo_text_emb)\n",
        "        mu_post = self.mu_posterior(h)\n",
        "        logvar_post = torch.clamp(self.logvar_posterior(h), min=-10, max=10)\n",
        "\n",
        "        # Reparameterization trick: sample z ~ N(mu, sigma^2)\n",
        "        std = torch.exp(0.5 * logvar_post)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu_post + eps * std\n",
        "\n",
        "        return z, mu_post, logvar_post"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei4TW7Oduic7"
      },
      "outputs": [],
      "source": [
        "class PriorNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Learns a prior distribution p(z | x)\n",
        "    based only on text (without emotion labels).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=768, latent_dim=128):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(256)\n",
        "        )\n",
        "        self.mu_prior = nn.Linear(256, latent_dim)\n",
        "        self.logvar_prior = nn.Linear(256, latent_dim)\n",
        "\n",
        "    def forward(self, text_emb):\n",
        "        h = self.mlp(text_emb)\n",
        "        mu_prior = self.mu_prior(h)\n",
        "        logvar_prior = torch.clamp(self.logvar_prior(h), min=-10, max=10)\n",
        "\n",
        "        return mu_prior, logvar_prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDlc2GUCu5er"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Final shared emotion classifier layer\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=128, num_classes=28):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.mlp(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRPwfGusvCgV"
      },
      "outputs": [],
      "source": [
        "# Main Model class\n",
        "class EmoAxis(nn.Module):\n",
        "    def __init__(self, encoder, cross_atten_module, posterior_net, prior_net, classifier):\n",
        "        \"\"\"\n",
        "        Architecture:\n",
        "        - EncoderBlock   → produces text and fused(text+emotion) embeddings\n",
        "        - PosteriorNet   → q(z|x,e)\n",
        "        - PriorNet       → p(z|x)\n",
        "        - EmotionClassifier → predicts emotions from latent z\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.cross_atten = cross_atten_module\n",
        "        self.posterior = posterior_net\n",
        "        self.prior = prior_net\n",
        "        self.classifier = classifier\n",
        "\n",
        "\n",
        "    def total_params(self):\n",
        "        \"\"\"Utility function to check trainable vs total params.\"\"\"\n",
        "        total = sum(p.numel() for p in self.parameters())\n",
        "        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "        print(f\"Total parameters: {total:,}\")\n",
        "        print(f\"Trainable parameters: {trainable:,}\")\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, atten_mask, emotion_labels, expressiveness):\n",
        "        # Encoder\n",
        "        encoder_outputs = self.encoder(\n",
        "            inputs = {\"input_ids\": input_ids, \"attention_mask\": atten_mask},\n",
        "        )\n",
        "        text_emb = encoder_outputs[\"text_embed\"]                  # [B, H]\n",
        "\n",
        "        # Cross Attention\n",
        "        fused_emb = self.cross_atten(encoder_outputs, emotion_labels, expressiveness)    # [B, H]\n",
        "\n",
        "        # Posterior Net\n",
        "        z_post, mu_post, logvar_post = self.posterior(fused_emb)\n",
        "\n",
        "        # Prior Net\n",
        "        mu_prior, logvar_prior = self.prior(text_emb)\n",
        "        z_prior = mu_prior + torch.exp(0.5 * logvar_prior) * torch.randn_like(mu_prior)\n",
        "\n",
        "        # 4. Classifier\n",
        "        logits_post = self.classifier(z_post)           # from sampled posterior\n",
        "        logits_prior = self.classifier(z_prior)         # from prior mean\n",
        "\n",
        "        return {\n",
        "            \"mu_post\": mu_post,\n",
        "            \"logvar_post\": logvar_post,\n",
        "            \"mu_prior\": mu_prior,\n",
        "            \"logvar_prior\": logvar_prior,\n",
        "            \"logits_post\": logits_post,\n",
        "            \"logits_prior\": logits_prior\n",
        "        }\n",
        "\n",
        "\n",
        "    def inference(self, input_ids, atten_mask):\n",
        "        \"\"\"\n",
        "        Predict emotions from raw text (inference using prior p(z|x)).\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = self.encoder(\n",
        "                inputs = {\"input_ids\": input_ids, \"attention_mask\": atten_mask},\n",
        "            )\n",
        "            # get only text embeddings\n",
        "            text_emb = encoder_outputs[\"text_embed\"]\n",
        "\n",
        "            # latent mean from prior\n",
        "            mu_prior, logvar_prior = self.prior(text_emb)\n",
        "\n",
        "            # classification\n",
        "            logits = self.classifier(mu_prior)\n",
        "\n",
        "            return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPOD0z9MvLXw",
        "outputId": "3f2d886d-aef7-4d4a-91e0-4cae3c0d701c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 127,674,012\n",
            "Trainable parameters: 127,674,012\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(base_encoder=roberta_base)\n",
        "\n",
        "cross_atten_module = CrossAttentionModule(label_embedding_dict=emo_embed)\n",
        "\n",
        "posterior_net = PosteriorNetwork()\n",
        "prior_net = PriorNetwork()\n",
        "classifier = Classifier()\n",
        "\n",
        "# Initialize model\n",
        "model = EmoAxis(\n",
        "    encoder=encoder,\n",
        "    cross_atten_module=cross_atten_module,\n",
        "    posterior_net=posterior_net,\n",
        "    prior_net=prior_net,\n",
        "    classifier=classifier\n",
        ")\n",
        "\n",
        "model.total_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKBNUb8wvLUZ"
      },
      "outputs": [],
      "source": [
        "def kl_divergence(mu_post, logvar_post, mu_prior, logvar_prior):\n",
        "    \"\"\"\n",
        "    KL(N(mu_q, var_q) || N(mu_p, var_p)) averaged over batch.\n",
        "    Uses diagonal covariance (logvar = log(sigma^2))\n",
        "\n",
        "    Formula: 0.5 * sum( log(var_p/var_q) + (var_q + (mu_q-mu_p)^2)/var_p - 1 )\n",
        "    \"\"\"\n",
        "    term = logvar_prior - logvar_post + (torch.exp(logvar_post) + (mu_post - mu_prior) ** 2) / torch.exp(logvar_prior) - 1.0\n",
        "    kl = 0.5 * torch.sum(term, dim=1)\n",
        "\n",
        "    return kl.mean()\n",
        "\n",
        "\n",
        "def compute_loss(logits_post, logits_prior, mu_post, logvar_post,\n",
        "                 mu_prior, logvar_prior, hard_target, soft_target,\n",
        "                 epoch, lambda_soft=1.0, lambda_kl=0.1):\n",
        "\n",
        "    # BCE - supervised (posterior only)\n",
        "    loss_bce = F.binary_cross_entropy_with_logits(logits_post, hard_target)\n",
        "\n",
        "    #Soft MSE - posterior and prior (sigmoid outputs)\n",
        "    probs_post = torch.sigmoid(logits_post)\n",
        "    loss_soft_post = F.mse_loss(probs_post, soft_target)\n",
        "    if epoch < 1:\n",
        "        loss_soft = loss_soft_post\n",
        "    else:\n",
        "        probs_prior = torch.sigmoid(logits_prior)\n",
        "        loss_soft_prior = F.mse_loss(probs_prior, soft_target)\n",
        "        loss_soft = loss_soft_post + loss_soft_prior\n",
        "\n",
        "    # KL Divergence between posterior and prior\n",
        "    loss_kl = kl_divergence(mu_post, logvar_post, mu_prior, logvar_prior)\n",
        "\n",
        "    # Total loss\n",
        "    total_loss = loss_bce + lambda_soft * loss_soft + lambda_kl * loss_kl\n",
        "\n",
        "    return total_loss, {\"loss_bce\": loss_bce.item(), \"loss_soft\": loss_soft.item(), \"loss_kl\": loss_kl.item()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go3rzqOPvLR4"
      },
      "outputs": [],
      "source": [
        "def freeze_encoder_layers(encoder=roberta_base, freeze_upto: int=0):\n",
        "    \"\"\"\n",
        "    Freezes encoder layers from 0 → freeze_upto (inclusive).\n",
        "    Example: freeze_upto = 5 → freeze encoder.layer[0] ... encoder.layer[5].\n",
        "    \"\"\"\n",
        "    for name, param in encoder.encoder.named_parameters():\n",
        "        param.requires_grad = True                      # unfreeze all layers\n",
        "\n",
        "    # freeze\n",
        "    for layer_idx in range(freeze_upto + 1):\n",
        "        for param in encoder.encoder.layer[layer_idx].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    print(f\"Frozen encoder layers - 0 to {freeze_upto}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bUEOGPtvYEI"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_dataloader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    preds_all = []\n",
        "    truths_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['atten_masks'].to(device)\n",
        "            hard_target = batch['hard_target'].to(device)\n",
        "\n",
        "            # inference\n",
        "            logits = model.inference(input_ids, attention_mask)\n",
        "\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            preds = (probs >= threshold).astype(int)\n",
        "            truths = hard_target.cpu().numpy().astype(int)\n",
        "\n",
        "            preds_all.append(preds)\n",
        "            truths_all.append(truths)\n",
        "\n",
        "    preds_all = np.concatenate(preds_all, axis=0)\n",
        "    truths_all = np.concatenate(truths_all, axis=0)\n",
        "\n",
        "    micro_f1 = f1_score(truths_all, preds_all, average='micro', zero_division=0)\n",
        "    macro_f1 = f1_score(truths_all, preds_all, average='macro', zero_division=0)\n",
        "\n",
        "    return {\"micro_f1\": micro_f1, \"macro_f1\": macro_f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl5hI5Y8wIDO"
      },
      "outputs": [],
      "source": [
        "# Main model training function\n",
        "def train(\n",
        "    model: nn.Module,\n",
        "    train_dataloader: DataLoader,\n",
        "    val_dataloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    epochs: int = 10,\n",
        "    lr_encoder: float = 2e-5,\n",
        "    lr_other: float = 1e-4,\n",
        "    weight_decay: float = 0.01,\n",
        "    warmup_ratio: float = 0.1,\n",
        "    kl_anneal_ratio: float = 0.25,\n",
        "    gradient_accumulation_steps: int = 4,\n",
        "    max_grad_norm: float = 1.0,\n",
        "    use_amp: bool = True,\n",
        "    early_stopping_patience: int = 3,\n",
        "    min_epochs_before_stop: int = 3\n",
        "):\n",
        "    model.to(device)\n",
        "\n",
        "    # Separate RoBERTa-encoder params &  other_params for different learning rate\n",
        "    encoder_params, other_params = [], []\n",
        "    for name, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if 'encoder' in name:\n",
        "            encoder_params.append(p)\n",
        "        else:\n",
        "            other_params.append(p)\n",
        "\n",
        "    optimizer = AdamW([\n",
        "        {\"params\": encoder_params, \"lr\": lr_encoder},\n",
        "        {\"params\": other_params, \"lr\": lr_other}\n",
        "    ], weight_decay=weight_decay)\n",
        "\n",
        "    steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
        "    total_steps = steps_per_epoch * epochs\n",
        "\n",
        "    warmup_steps = int(total_steps * warmup_ratio)\n",
        "    kl_anneal_steps = int(total_steps * kl_anneal_ratio)\n",
        "\n",
        "    # Build scheduler based on step count\n",
        "    scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_warmup_steps=warmup_steps,\n",
        "                num_training_steps=total_steps\n",
        "            )\n",
        "\n",
        "    scaler = GradScaler(enabled=(use_amp and device.type =='cuda'))\n",
        "\n",
        "    global_step = 0\n",
        "    best_val_microF1 = -1.0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(0, epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # gradual encoder layers freezing\n",
        "        if epoch < 2:\n",
        "            freeze_encoder_layers(freeze_upto=5)         # Train last 6 layers only\n",
        "        elif epoch < 4:\n",
        "            freeze_encoder_layers(freeze_upto=3)         # Train last 8 layers\n",
        "        else:\n",
        "            freeze_encoder_layers(freeze_upto=-1)        # Train all layers\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            atten_mask = batch['atten_masks'].to(device)\n",
        "            labels = batch['label_names']\n",
        "            expressiveness = batch['expressiveness']\n",
        "            hard_target = batch['hard_target'].to(device)\n",
        "            soft_target = batch['soft_target'].to(device)\n",
        "\n",
        "            with autocast(device_type='cuda', dtype=torch.bfloat16, enabled=use_amp):\n",
        "                outputs = model(input_ids=input_ids,\n",
        "                                atten_mask=atten_mask,\n",
        "                                emotion_labels=labels,\n",
        "                                expressiveness=expressiveness)\n",
        "\n",
        "                logits_post = outputs['logits_post']\n",
        "                logits_prior = outputs['logits_prior']\n",
        "                mu_post, logvar_post = outputs['mu_post'], outputs['logvar_post']\n",
        "                mu_prior, logvar_prior = outputs['mu_prior'], outputs['logvar_prior']\n",
        "\n",
        "                # KL weight annealing schedule\n",
        "                kl_weight = min(1.0, global_step / max(1, kl_anneal_steps))\n",
        "\n",
        "                total_loss, _ = compute_loss(\n",
        "                    logits_post, logits_prior,\n",
        "                    mu_post, logvar_post, mu_prior, logvar_prior,\n",
        "                    hard_target, soft_target,\n",
        "                    epoch=epoch, lambda_kl=kl_weight\n",
        "                )\n",
        "                # Normalize loss for gradient accumulation\n",
        "                total_loss = total_loss / gradient_accumulation_steps\n",
        "\n",
        "            # Backward\n",
        "            scaler.scale(total_loss).backward()\n",
        "\n",
        "            if (step + 1) % gradient_accumulation_steps == 0 or (step + 1) == len(train_dataloader):\n",
        "                # gradient clipping\n",
        "                scaler.unscale_(optimizer)\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "            epoch_loss += total_loss.item() * gradient_accumulation_steps\n",
        "            avg_loss = epoch_loss / len(train_dataloader)\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        metrics = validate(model, val_dataloader, device)\n",
        "        micro_F1 = metrics.get(\"micro_f1\", -1)\n",
        "        macro_F1 = metrics.get(\"macro_f1\", -1)\n",
        "        print(f\"Validation: micro-F1 = {micro_F1:.4f}, macro-F1 = {macro_F1:.4f}\")\n",
        "\n",
        "        if micro_F1 > best_val_microF1:\n",
        "            best_val_microF1 = micro_F1\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), os.path.join(\"model_dir\", \"best_model.pt\"))                # ENTER MODEL DIR PATH FOR SAVING MODEL\n",
        "            print(\"Micro-F1 score improved — model saved.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "        # Early Stopping\n",
        "        if epoch + 1 >= min_epochs_before_stop and epochs_no_improve >= early_stopping_patience:\n",
        "            print(\"\\nEarly stopping activated.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\n\\nTraining completed. Best validation micro-F1 = {best_val_microF1:.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "hTOEhHxMxLrf",
        "outputId": "e4faaf41-43b7-4d0b-87af-26ca2531b008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frozen encoder layers - 0 to 5\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'frustration'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-425896434.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-248634684.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, device, epochs, lr_encoder, lr_other, weight_decay, warmup_ratio, kl_anneal_ratio, gradient_accumulation_steps, max_grad_norm, use_amp, early_stopping_patience, min_epochs_before_stop)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 outputs = model(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     79\u001b[0m                                 \u001b[0matten_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matten_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                                 \u001b[0memotion_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-465311044.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, atten_mask, emotion_labels, expressiveness)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Cross Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mfused_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_atten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpressiveness\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# [B, H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Posterior Net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2526776737.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_out, emotion_labels, expressiveness)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpressiveness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# stack embeddings of all emotion descriptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0memb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_embedding_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0memb_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m                                                       \u001b[0;31m# [num_labels, H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'frustration'"
          ]
        }
      ],
      "source": [
        "train(model=model, train_dataloader=train_dataloader, val_dataloader=val_dataloader, device=device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}